{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import inspect\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, parameters): \n",
    "    \"\"\"\n",
    "    Runs forward propagation on z and parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    z -- noise\n",
    "    parameters -- neural net weights\n",
    "    \n",
    "    Returns:\n",
    "    z -- output of last activation layer\n",
    "    \"\"\"\n",
    "    z = z.t()\n",
    "    z = parameters['W1'] @ z + parameters['b1']\n",
    "    z = F.relu(z)\n",
    "    z = parameters['W2'] @ z + parameters['b2']\n",
    "    z = F.relu(z)\n",
    "    z = parameters['W3'] @ z + parameters['b3']\n",
    "    z = F.relu(z)\n",
    "    return z.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.sort(torch.Tensor(16384, 1).uniform_(-1, 1), dim=0)[0]\n",
    "Y = torch.sort(torch.Tensor(16384, 1).normal_(), dim=0)[0]\n",
    "dataset = torch.utils.data.TensorDataset(X, Y, )\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "parameters = {'W1': torch.nn.init.xavier_uniform_(torch.zeros((64,1), requires_grad=True)),\n",
    "              'b1': torch.nn.init.xavier_uniform_(torch.zeros((64, 1), requires_grad=True)),\n",
    "'W2': torch.nn.init.xavier_uniform_(torch.zeros((64,64), requires_grad=True)),\n",
    "              'b2': torch.nn.init.xavier_uniform_(torch.zeros((64, 1), requires_grad=True)),\n",
    "    'W3': torch.nn.init.xavier_uniform_(torch.zeros((1, 64),requires_grad=True)),\n",
    "              'b3': torch.nn.init.xavier_uniform_(torch.zeros((1, 1), requires_grad=True)),\n",
    "}\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam([theta_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 500, Loss: 1.0099876532554626\n",
      "Epoch: 1, Batch: 500, Loss: 1.0081790161728859\n",
      "Epoch: 2, Batch: 500, Loss: 1.0090901383757591\n",
      "Epoch: 3, Batch: 500, Loss: 1.009838389158249\n",
      "Epoch: 4, Batch: 500, Loss: 1.0083738174438477\n",
      "Epoch: 5, Batch: 500, Loss: 1.010081649363041\n",
      "Epoch: 6, Batch: 500, Loss: 1.0093683307170869\n",
      "Epoch: 7, Batch: 500, Loss: 1.008346579492092\n",
      "Epoch: 8, Batch: 500, Loss: 1.0106085485816\n",
      "Epoch: 9, Batch: 500, Loss: 1.0115783071517945\n",
      "Epoch: 10, Batch: 500, Loss: 1.0099775834083558\n",
      "Epoch: 11, Batch: 500, Loss: 1.0100039891004562\n",
      "Epoch: 12, Batch: 500, Loss: 1.0103229751586915\n",
      "Epoch: 13, Batch: 500, Loss: 1.0067710070610045\n",
      "Epoch: 14, Batch: 500, Loss: 1.007408028423786\n",
      "Epoch: 15, Batch: 500, Loss: 1.0086628034114837\n",
      "Epoch: 16, Batch: 500, Loss: 1.0092539191246033\n",
      "Epoch: 17, Batch: 500, Loss: 1.0091418281197548\n",
      "Epoch: 18, Batch: 500, Loss: 1.0070842928290367\n",
      "Epoch: 19, Batch: 500, Loss: 1.0077803265452385\n",
      "Epoch: 20, Batch: 500, Loss: 1.0121375247240068\n",
      "Epoch: 21, Batch: 500, Loss: 1.0084016752243041\n",
      "Epoch: 22, Batch: 500, Loss: 1.008597884476185\n",
      "Epoch: 23, Batch: 500, Loss: 1.0112024330496787\n",
      "Epoch: 24, Batch: 500, Loss: 1.0099440351724625\n",
      "Epoch: 25, Batch: 500, Loss: 1.00646999835968\n",
      "Epoch: 26, Batch: 500, Loss: 1.008876460313797\n",
      "Epoch: 27, Batch: 500, Loss: 1.0104501702189446\n",
      "Epoch: 28, Batch: 500, Loss: 1.006648839354515\n",
      "Epoch: 29, Batch: 500, Loss: 1.0084984310865401\n",
      "Epoch: 30, Batch: 500, Loss: 1.006539405465126\n",
      "Epoch: 31, Batch: 500, Loss: 1.0087566324472428\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-585b14a77198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Why...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad() # Why...\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        outputs = generator(inputs, parameters)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        modulus = 500\n",
    "        if (batch_idx % modulus == 0 and batch_idx > 0):\n",
    "            print(F\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {running_loss/modulus}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1230b79b0>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121cd16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(z.numpy())\n",
    "plot(y.numpy())\n",
    "plot(generator(X, parameters).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-75-81eba2ed299d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-81eba2ed299d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    #Returns scalar probability that x comes from data rather than generator\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def discriminator(x, theta_d): \n",
    "    #x:=input sample\n",
    "    #theta_d:=neural net params\n",
    "    #Returns scalar probability that x comes from data rather than generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
